<div align="center">

Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction




</div>

<!-- å»ºè®®åœ¨è¿™é‡Œæ”¾ä¸€å¼  teaser å›¾ç‰‡æˆ– GIF åŠ¨å›¾ï¼Œå±•ç¤ºä½ çš„æ ¸å¿ƒæ•ˆæœ -->

<p align="center">
<img src="assets/teaser.jpg" alt="Teaser Image" width="400"/>





</p>


## ğŸ“° News

<!-- è®°å½•é¡¹ç›®çš„æ›´æ–°æ—¥å¿— -->

[2025-12-02] Annotate app code released!

[2025-12-03] 4DHOISolver code released!

## ğŸš€ To Do

[x] Release core inference code.

[ ] Release Automatic 4DHOI Reconstruction Code.

[ ] Release Dataset

## ğŸ› ï¸ Installation


```
# Clone this repository

```


## ğŸ–¥ï¸  Annotate app

### Data Preparation
You can download the test data from [Google Drive](https://drive.google.com/uc?export=download&id=1a9iUSfuuBrB2q6iewi4uxMAB9XIrvuJo) and place it in ./demo.

The data structure should be like this:
```
./demo
â”œâ”€â”€ align ## depth alignment result for initialization
â”œâ”€â”€ motion ## motion reconstruction from GVHMR
â”œâ”€â”€ video 
â””â”€â”€ obj_org.obj ## object model
```

### Install
please follow https://github.com/facebookresearch/co-tracker to install co-tracker.

```
cd Annot-app/co-tracker
pip install -e .
```

### Usage
See `Annot-app/co-tracker/README.md` for more details.






## ğŸ“– Citation

If you find this code useful for your research, please consider citing our paper:

<!-- æ›¿æ¢ä¸ºä½ çš„ BibTeX -->
```

```